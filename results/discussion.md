The model performed well, but not overwhelmingly. Accuracy, precision, recall and f score did not exceed 80% on validation, though whether this could have been achieved with additional training is unclear. On multiclass problems such as MNIST, neural networks can achieve accuracy scores over 95%, and we expected to see similar performance given the dataset provided had over a hundred features. It was also disappointing to see the performance imbalances stay incorrected - classes that needed more focus could have perhaps been prioritised via gradient-boosting, which presents an opportunity for further inquiry.

The solution was fast, but still took a long time to achieve. Part of this was the reporting and printing overhead - if the user can tolerate a worse granularity on training progress, there would be some improvement in training times. The size of the neural network was also a factor, with 500 nodes in each hidden layer increasing the training resources required.
